# ObsidianEcho-AI Configuration Example
# Copy this file to main.yaml and customize

# Application Settings
app_name: "ObsidianEcho-AI"
version: "0.1.0"
debug: false

# Server Settings
host: "0.0.0.0"
port: 8000

# Logging
log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
log_format: "json"  # json or text

# CORS Settings
cors_origins:
  - "*"  # Configure for production

# AI Provider Settings
# API keys must be set via environment variables:
#   - OpenAI: export OPENAI_API_KEY="sk-..."  (get from https://platform.openai.com/api-keys)
#   - XAI:    export XAI_API_KEY="xai-..."    (get from https://console.x.ai)
providers:
  # Default provider to use when none is specified
  default_provider: "openai"

  # OpenAI Configuration
  openai:
    enabled: true
    model: "gpt-4o"  # Options: gpt-4o, gpt-4-turbo, gpt-3.5-turbo, etc.
    timeout_seconds: 60
    max_retries: 3

  # xAI Configuration (optional)
  xai:
    enabled: false
    model: "grok-beta"  # Options: grok-beta, grok-2, etc.
    timeout_seconds: 60
    max_retries: 3

# Agent Settings (to be added in future stories)
# agents:
#   research:
#     default_depth: "standard"
#     timeout_seconds: 300
#   template:
#     templates_dir: "config/templates"

# Rate Limiting (to be added in future stories)
# rate_limits:
#   default:
#     requests_per_minute: 10
#     requests_per_hour: 100

# Task Queue (to be added in future stories)
# task_queue:
#   max_workers: 4
#   task_timeout_seconds: 600
